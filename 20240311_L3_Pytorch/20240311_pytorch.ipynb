{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40937e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\anaconda3\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87498d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6603baad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[Tensor란?]\\n Tensor는 배열(Array)나 행렬(Matrix)와 유사한 자료구조이다. 3차원 이상의 배열을 의미한다.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "[Tensor란?]\n",
    " Tensor는 배열(Array)나 행렬(Matrix)와 유사한 자료구조이다. 3차원 이상의 배열을 의미한다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11da35fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Directly Tensor(1X3): \n",
      "tensor([0, 1, 2])\n",
      "\n",
      "2. Directly Tensor(2X2): \n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "3. Random Tensor: \n",
      " tensor([[[0.1324, 0.8541, 0.6663, 0.2381, 0.1043],\n",
      "         [0.8293, 0.0162, 0.3532, 0.1041, 0.8139],\n",
      "         [0.0909, 0.0784, 0.6062, 0.6425, 0.9112]],\n",
      "\n",
      "        [[0.5011, 0.3974, 0.6707, 0.6391, 0.2410],\n",
      "         [0.8604, 0.5790, 0.4575, 0.9339, 0.4805],\n",
      "         [0.0153, 0.4082, 0.3602, 0.1661, 0.2644]]]) \n",
      "\n",
      "4. RandomN Tensor: \n",
      " tensor([[[-0.5737, -0.6161, -0.4316, -0.0089, -2.5238],\n",
      "         [-0.0636, -0.6922, -0.4196, -2.1533,  0.4160],\n",
      "         [ 0.6889,  0.6513,  1.0776,  0.6627,  0.3694]],\n",
      "\n",
      "        [[-0.9533,  1.2490, -1.5474,  0.7235, -0.4958],\n",
      "         [-0.5179, -0.4627,  0.7354,  0.9678, -0.2472],\n",
      "         [-0.4332, -0.9856, -0.6637, -0.1136,  0.8546]]]) \n",
      "\n",
      "5. Ones Tensor: \n",
      " tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]]) \n",
      "\n",
      "6. Zeros Tensor: \n",
      " tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "\n",
      "7. Zeros Tensor Long: \n",
      " tensor([[[0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0]]])\n",
      "\n",
      "8-1. Random Tensor: \n",
      " tensor([[[0.1324, 0.8541, 0.6663, 0.2381, 0.1043],\n",
      "         [0.8293, 0.0162, 0.3532, 0.1041, 0.8139],\n",
      "         [0.0909, 0.0784, 0.6062, 0.6425, 0.9112]],\n",
      "\n",
      "        [[0.5011, 0.3974, 0.6707, 0.6391, 0.2410],\n",
      "         [0.8604, 0.5790, 0.4575, 0.9339, 0.4805],\n",
      "         [0.0153, 0.4082, 0.3602, 0.1661, 0.2644]]])\n",
      "8-2. Random Tensor Info: \n",
      " Shapetorch.Size([2, 3, 5]), Typetorch.float32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Tensor Creation\n",
    "\"\"\"\n",
    "## 1.1. 직접 생성\n",
    "onebythree = torch.tensor([0, 1, 2]) # 1x3 배열\n",
    "twobytwo = torch.tensor([[1, 2], [3, 4]]) # 2X2 배열\n",
    "\n",
    "print(f\"1. Directly Tensor(1X3): \\n{onebythree}\\n\")\n",
    "print(f\"2. Directly Tensor(2X2): \\n{twobytwo}\\n\")\n",
    "\n",
    "## 1.2. 무작위 또는 상수 값 사용(shape는 맘대로 선택하세요)\n",
    "# shape = (2, 3,) # 2 x 3 배열\n",
    "# shape = (3,) # 원소가 3개인 1차원 배열(벡터)\n",
    "shape = (2, 3, 5,) # 2 x 3 x 5배열\n",
    "\n",
    "### torch.rand(): 0과 1 사이의 균일 분포에서 난수를 생성합니다. 모든 값은 동일한 확률로 나타납니다.\n",
    "rand_tensor = torch.rand(shape)\n",
    "\n",
    "### torch.randn(): 평균이 0이고 표준편차가 1인 정규 분포에서 난수를 생성합니다. 값이 0에 가까울수록 더 높은 확률로 난수가 발생합니다.\n",
    "randn_tensor = torch.randn(shape)\n",
    "\n",
    "### torch.ones(): 모든 원소가 1로 이루어진 텐서를 생성합니다.\n",
    "ones_tensor = torch.ones(shape)\n",
    "\n",
    "### torch.zeros(): 모든 원소가 0으로 이루어진 텐서를 생성합니다.\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "zeros_tensor_long = torch.zeros(shape, dtype=torch.long) # dtype 으로 타입을 지정할 수 있다. \n",
    "                                                         # 지정하지 않으면 torch.float32(32비트 부동소수점)으로 세팅된다.\n",
    "\n",
    "print(f\"3. Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"4. RandomN Tensor: \\n {randn_tensor} \\n\")\n",
    "print(f\"5. Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"6. Zeros Tensor: \\n {zeros_tensor}\\n\")\n",
    "print(f\"7. Zeros Tensor Long: \\n {zeros_tensor_long}\\n\")\n",
    "\n",
    "## 1.3. 텐서의 표현\n",
    "scalar = torch.tensor(3) # 스칼라 값을 가진 0차원 Tensor\n",
    "vector = torch.tensor([3]) # 1개의 원소를 갖는 1차원 배열(벡터)\n",
    "\n",
    "## 1.4. 텐서의 속성\n",
    "print(f\"8-1. Random Tensor: \\n {rand_tensor}\")\n",
    "print(f\"8-2. Random Tensor Info: \\n Shape{rand_tensor.shape}, Type{rand_tensor.dtype} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51314132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sum Result:\n",
      " tensor([[-1.3773,  1.1670, -1.1702],\n",
      "        [ 0.3788,  0.0095, -0.9695],\n",
      "        [-1.0166, -0.9536,  0.3716]])\n",
      "\n",
      "2. Minus Result:\n",
      " tensor([[-3.7331, -4.0198, -0.4647],\n",
      "        [ 0.3497, -0.1531, -0.5073],\n",
      "        [-0.2506, -1.1824, -0.1668]])\n",
      "\n",
      "3. Elementwise Multiplication Result:\n",
      " tensor([[-3.0097, -3.6991,  0.2884],\n",
      "        [ 0.0053, -0.0058,  0.1706],\n",
      "        [ 0.2427, -0.1222,  0.0276]])\n",
      "\n",
      "4. Elementwise Division Result:\n",
      " tensor([[-2.1693, -0.5500,  2.3174],\n",
      "        [25.0750, -0.8834,  3.1950],\n",
      "        [ 1.6544, -9.3352,  0.3803]])\n",
      "\n",
      "5. Matrix Multiplication Result:\n",
      " tensor([[-2.7174, -6.8361,  1.0109],\n",
      "        [ 0.7108,  0.8543, -0.3107],\n",
      "        [-0.8010, -1.7183,  0.4979]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2. Tensor Operation\n",
    "\"\"\"\n",
    "# 2.1. 텐서 생성\n",
    "tensor_a = torch.randn(3, 3)  # 3x3 크기의 무작위 행렬 생성\n",
    "tensor_b = torch.randn(3, 3)  # 3x3 크기의 무작위 행렬 생성\n",
    "\n",
    "# 2.2. 텐서 연산\n",
    "sum_result = tensor_a + tensor_b  # 행렬 덧셈\n",
    "minus_result = tensor_a - tensor_b  # 행렬 뺄셈\n",
    "elementwise_mul_result = tensor_a * tensor_b  # 요소별 곱셈\n",
    "elementwise_div_result = tensor_a / tensor_b  # 요소별 나눗셈\n",
    "matrix_mul_result = tensor_a @ tensor_b  # 행렬 곱셈\n",
    "\n",
    "# 2.3. 결과 출력\n",
    "print(\"1. Sum Result:\\n\", sum_result)\n",
    "print(\"\\n2. Minus Result:\\n\", minus_result)\n",
    "print(\"\\n3. Elementwise Multiplication Result:\\n\", elementwise_mul_result)\n",
    "print(\"\\n4. Elementwise Division Result:\\n\", elementwise_div_result)\n",
    "print(\"\\n5. Matrix Multiplication Result:\\n\", matrix_mul_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91720dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "\n",
      "Matrix B:\n",
      " tensor([[10],\n",
      "        [20],\n",
      "        [30]])\n",
      "\n",
      "Result after Broadcasting:\n",
      " tensor([[11, 12, 13],\n",
      "        [24, 25, 26],\n",
      "        [37, 38, 39]])\n",
      "\n",
      "Error: RuntimeError - The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3. 브로드캐스팅\n",
    " 텐서 간에 크기가 서로 다른 경우에 자동으로 크기를 맞추어 연산을 수행하는 기능이다.\n",
    "\"\"\"\n",
    "# 크기가 (3, 3)인 행렬\n",
    "A = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "# 크기가 (3, 1)인 열 벡터\n",
    "B = torch.tensor([[10],\n",
    "                  [20],\n",
    "                  [30]])\n",
    "\n",
    "# 브로드캐스팅을 사용한 행렬 덧셈\n",
    "result = A + B\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Matrix A:\\n\", A)\n",
    "print(\"\\nMatrix B:\\n\", B)\n",
    "print(\"\\nResult after Broadcasting:\\n\", result)\n",
    "\n",
    "\"\"\"\n",
    "3-1. 브로드캐스팅이 불가한 경우: 두 텐서의 차원이 서로 호환되지 않을 때 발생한다.\n",
    "\"\"\"\n",
    "# 크기가 (3, 3)인 행렬\n",
    "A = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "# 크기가 (2, 3)인 행렬\n",
    "B = torch.tensor([[10, 20, 30],\n",
    "                  [40, 50, 60]])\n",
    "\n",
    "# 브로드캐스팅을 시도하면 에러가 발생\n",
    "try:\n",
    "    result = A + B\n",
    "except Exception as e:\n",
    "    print(f\"\\nError: {type(e).__name__} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "142f4ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Element at index (1, 2): 6\n",
      "\n",
      "2. Row at index 1: tensor([4, 5, 6])\n",
      "\n",
      "3. Column at index 2: tensor([3, 6, 9])\n",
      "\n",
      "4. Rows from index 0 to 1: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "5. Columns from index 0 to 1: \n",
      "tensor([[1, 2],\n",
      "        [4, 5],\n",
      "        [7, 8]])\n",
      "\n",
      "6-1. Result using slicing: tensor(5)\n",
      "\n",
      "6-2. Result using fancy indexing: tensor([5])\n",
      "\n",
      "6-3. Result using fancy indexing2: tensor([5, 6])\n",
      "\n",
      "6-4. Result using fancy indexing3: tensor([5])\n",
      "\n",
      "6-5. Result using fancy indexing4: tensor([5])\n",
      "\n",
      "7-1. Original Tensor: tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "\n",
      "7-2. Reshaped Tensor (2x4): tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "\n",
      "7-3. Reshaped Tensor (2x2x2): tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "\n",
      "8-1. Original Tensor: tensor([42])\n",
      "\n",
      "8-2. Scalar Value using .item(): 42\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4. Slicing/Indexing\n",
    "\"\"\"\n",
    "# 예시 텐서 생성\n",
    "example = torch.tensor([[1, 2, 3],\n",
    "                      [4, 5, 6],\n",
    "                      [7, 8, 9]])\n",
    "\n",
    "# 특정 원소에 접근\n",
    "element_at_index_1_2 = example[1, 2]\n",
    "print(f\"1. Element at index (1, 2): {element_at_index_1_2}\")\n",
    "\n",
    "# 행 접근\n",
    "row_1 = example[1, :]\n",
    "row_1 = example[1] # 둘이 같음\n",
    "print(f\"\\n2. Row at index 1: {row_1}\")\n",
    "\n",
    "# 열 접근\n",
    "column_2 = example[:, 2]\n",
    "print(f\"\\n3. Column at index 2: {column_2}\")\n",
    "\n",
    "# 특정 범위의 행 슬라이싱\n",
    "rows_slice = example[0:2, :]\n",
    "print(f\"\\n4. Rows from index 0 to 1: \\n{rows_slice}\")\n",
    "\n",
    "# 특정 범위의 열 슬라이싱\n",
    "columns_slice = example[:, 0:2]\n",
    "print(f\"\\n5. Columns from index 0 to 1: \\n{columns_slice}\")\n",
    "\n",
    "# Fancy Indexing\n",
    "row_1_slicing = example[1, 1]\n",
    "row_1_fancy_indexing = example[1, [1]]\n",
    "row_1_fancy_indexing2 = example[1, [1, 2]]\n",
    "row_1_fancy_indexing3 = example[[1], 1]\n",
    "row_1_fancy_indexing4 = example[[1], [1]]\n",
    "\n",
    "print(\"\\n6-1. Result using slicing:\", row_1_slicing)\n",
    "print(\"\\n6-2. Result using fancy indexing:\", row_1_fancy_indexing)\n",
    "print(\"\\n6-3. Result using fancy indexing2:\", row_1_fancy_indexing2)\n",
    "print(\"\\n6-4. Result using fancy indexing3:\", row_1_fancy_indexing3)\n",
    "print(\"\\n6-5. Result using fancy indexing4:\", row_1_fancy_indexing4)\n",
    "\n",
    "# Reshape() : 텐서의 크기를 변경하거나 모양을 조정하는 데 사용됨\n",
    "tensor = torch.arange(1, 9)  # [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "print(\"\\n7-1. Original Tensor:\", tensor)\n",
    "\n",
    "# reshape를 사용하여 크기 변경\n",
    "reshaped_tensor = tensor.reshape(2, 4)\n",
    "print(\"\\n7-2. Reshaped Tensor (2x4):\", reshaped_tensor)\n",
    "\n",
    "reshaped_tensor_2x2x2 = tensor.reshape(2, 2, 2)\n",
    "print(\"\\n7-3. Reshaped Tensor (2x2x2):\", reshaped_tensor_2x2x2)\n",
    "\n",
    "# .item(): 단일 원소 값을 Python의 기본 데이터 타입으로 변환하는 메서드. 주로 스칼라 값으로만 존재하는 텐서에서 사용.\n",
    "tensor = torch.tensor([42])\n",
    "scalar_value = tensor.item()\n",
    "\n",
    "print(\"\\n8-1. Original Tensor:\", tensor)\n",
    "print(\"\\n8-2. Scalar Value using .item():\", scalar_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "01d5f0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Original Tensor: tensor([ 0.8236,  0.0061, -0.7713, -0.0784, -0.1721])\n",
      "\n",
      "2. Sin Values: tensor([ 0.7336,  0.0061, -0.6971, -0.0783, -0.1712])\n",
      "3. Cos Values: tensor([0.6796, 1.0000, 0.7170, 0.9969, 0.9852])\n",
      "4. Tan Values: tensor([ 1.0796,  0.0061, -0.9722, -0.0785, -0.1738])\n",
      "\n",
      "5. Absolute Values: tensor([0.8236, 0.0061, 0.7713, 0.0784, 0.1721])\n",
      "6. Exponential Values: tensor([2.2788, 1.0062, 0.4624, 0.9246, 0.8419])\n",
      "7. Logarithmic Values: tensor([-0.1940, -5.0922,     nan,     nan,     nan])\n",
      "8. Square Root of Absolute Values: tensor([0.9075, 0.0784, 0.8782, 0.2799, 0.4148])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "5. Functions\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "# 예시 텐서 생성\n",
    "a = torch.randn(5)\n",
    "print(\"1. Original Tensor:\", a)\n",
    "\n",
    "# 삼각함수 예시\n",
    "sin_values = torch.sin(a)\n",
    "cos_values = torch.cos(a)\n",
    "tan_values = torch.tan(a)\n",
    "\n",
    "print(\"\\n2. Sin Values:\", sin_values)\n",
    "print(\"3. Cos Values:\", cos_values)\n",
    "print(\"4. Tan Values:\", tan_values)\n",
    "\n",
    "# 기본 수학 함수 예시\n",
    "abs_values = torch.abs(a)\n",
    "exp_values = torch.exp(a)\n",
    "log_values = torch.log(a)\n",
    "sqrt_values = torch.sqrt(torch.abs(a))  # sqrt에는 음수가 들어갈 수 없으므로 abs를 사용\n",
    "\n",
    "print(\"\\n5. Absolute Values:\", abs_values)\n",
    "print(\"6. Exponential Values:\", exp_values)\n",
    "print(\"7. Logarithmic Values:\", log_values)\n",
    "print(\"8. Square Root of Absolute Values:\", sqrt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "307000ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2373, -0.7248],\n",
      "        [ 1.5264, -0.7035]], requires_grad=True)\n",
      "tensor(0.6319, grad_fn=<MeanBackward0>)\n",
      "tensor([[-0.0588,  0.1657],\n",
      "        [-0.2498,  0.1617]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "6. Gradient\n",
    " 자동 미분: 자동 미분은 각 매개변수(주어진 입력)에 대한 손실 함수의 기울기를 계산할 수 있게 해준다. \n",
    "            함수의 출력이 스칼라일 때, 각 입력에 대한 편미분을 계산한다. \n",
    "            requires_grad=True 선언 시, 반드시 부동소수점 또는 복소수 데이터 타입으로 입력해야한다.\n",
    "\"\"\"\n",
    "a = torch.randn(2, 2, requires_grad=True) # Requires_grad=True: 자동미분 활성화\n",
    "b = a.cos().mean() # 스칼라값(a의 각 원소에 대해 삼각함수 적용 후 평균 값)\n",
    "b.backward() # 역전파를 시작함 b에 대한 a의 기울기를 계산한다. 각 원소에 대한 편미분이 a.grad에 저장됨.\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(a.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
